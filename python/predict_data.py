import pandas as pd
import numpy as np

# Normalise input variables [0.0, 1.0]
def normalise(data):
	# Cast as float32
	data = data.astype(np.float32)
	# Normalise [0.0, 1.0]
	data_norm = data.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))
	return data_norm

# One hot encoding for categorical variables
def one_hot_dataframe(data,replace=True):
	cols = data.columns[data.dtypes == 'object']
	for col in cols:
		print 'One hot encoding: '+col
		# Generate One Hot Encoding
		df = pd.get_dummies(data[col],prefix=col)   
		# Drop (UNKNOWN) column to remove multi-colinearity
		df.drop(df.columns[0],axis=1,inplace=True)
		# Add encoding to data
		data = pd.concat([data,df],axis=1)
		# Drop categorical column from data
		if replace is True:
			data.drop(col,axis=1,inplace=True)
	return data

# Define inputs
input_labels = ["ENTITY_NO","AGE","GENDER","FAMILY_SIZE","FAMILY_COMP_GRPD","OVERALL_SES","PLAN_MOVEMENT_KEY","LIFE","DDI","PSI","DMI","INCOME_BAND_KEY","UNDERWRITING_STATUS","ONCOLOGY_KEY","DURATION_INSURED","HVM","FUB","RUB","READMISSION_30_DAY_COUNT","EMERGENCY_VISIT_COUNT","IN_PATIENT_HOSP_COUNT","IN_PATIENT_HOSP_DAYS","CHRONIC_CONDITION_COUNT","DEG_CODE","PREV_DEG_CODE_1","AMOUNT_CLAIMED","IN_OUT_HOSPITAL","PROCEDURE_COUNT","BILLING_PRACTICE_TYPE","TOTAL_CLAIMS_IPM","TOTAL_CLAIMS_IPM3","TOTAL_CLAIMS_IPM6","TOTAL_CLAIMS_IPM12","TOTAL_CLAIM_AMOUNT_IPM","TOTAL_CLAIM_AMOUNT_IPM3","TOTAL_CLAIM_AMOUNT_IPM6","TOTAL_CLAIM_AMOUNT_IPM12","TOTAL_PROCS_IPM","TOTAL_PROCS_IPM3","TOTAL_PROCS_IPM6","TOTAL_PROCS_IPM12","WEIGHT","HEIGHT","WAIST","CHOLESTEROL","SYS_BP","DIA_BP","RANDOM_GLUCOSE","CIGS","DRINKS","FRUITVEG","DELTA_VA","PROP_OF_BENEFITS","HAS_GYM","GYM_FIRST_USE","DEDICATED_GYMMER","GYM_DANGER_ZONE","PHYSICAL_ACTIVITY_EVENTS_APM6","PHYSICAL_ACTIVITY_EVENTS_APM12","PHYSICAL_ACTIVITY_EVENTS_APM36","PHYSICAL_ACTIVITY_POINTS_APM6","PHYSICAL_ACTIVITY_POINTS_APM12","PHYSICAL_ACTIVITY_POINTS_APM36","PREFERRED_PARTNER","HF_GROUP","PARTNER_USAGE_SELECTION","UNHEALTHY_BEVERAGES_PER_MEMBER","CONFECTIONARY_PER_MEMBER","DAIRY_PER_MEMBER","PRE_PREPARED_MEALS_PER_MEMBER","FATS_OILS_PER_MEMBER","FRUIT_PER_MEMBER","VEGETABLES_PER_MEMBER","PROTEIN_PER_MEMBER","STARCHY_FOODS_PER_MEMBER","HEALTHY_FOOD_PER_MEMBER","UNHEALTHY_FOOD_PER_MEMBER","NEUTRAL_FOOD_PER_MEMBER","FAT_FREE_GOODS_PER_MEMBER","TOTAL_SPEND_PER_MEMBER","UNHEALTHY_BEVERAGES_COUNT_PER_MEMBER","CONFECTIONARY_COUNT_PER_MEMBER","DAIRY_COUNT_PER_MEMBER","PRE_PREPARED_MEALS_COUNT_PER_MEMBER","FATS_OILS_COUNT_PER_MEMBER","FRUIT_COUNT_PER_MEMBER","VEGETABLES_COUNT_PER_MEMBER","PROTEIN_COUNT_PER_MEMBER","STARCHY_FOODS_COUNT_PER_MEMBER","HEALTHY_FOOD_COUNT_PER_MEMBER","UNHEALTHY_FOOD_COUNT_PER_MEMBER","NEUTRAL_FOOD_COUNT_PER_MEMBER","FAT_FREE_GOODS_COUNT_PER_MEMBER","TOTAL_COUNT_PER_MEMBER","GYM_SPEND_APM3","GYM_SPEND_APM6","GYM_SPEND_APM12","TOTAL_TRNS_APM12","TOTAL_SPEND_SWIPES_APM12","DAYS_BETWEEN_TRNS_APM12","UTILIZATION_APM12","SIC_CODE_GROUPS_DISTINCT_APM12","FAST_FOOD_SPEND_APM3","FAST_FOOD_SPEND_APM6","FAST_FOOD_SPEND_APM12","FAST_FOOD_COUNT_APM3","FAST_FOOD_COUNT_APM6","FAST_FOOD_COUNT_APM12","DAYS_BETWEEN_FAST_FOOD","DAYS_BETWEEN_FAST_FOOD_APM12","HAS_MOVIE","SERIAL_MOVIEGOER","MOVIES_WATCHED_APM3","MOVIES_WATCHED_APM6","MOVIES_WATCHED_APM12","MOVIE_THEATER_SPEND_APM3","MOVIE_THEATER_SPEND_APM6","MOVIE_THEATER_SPEND_APM12","MOVIE_THEATER_COUNT_APM3","MOVIE_THEATER_COUNT_APM6","MOVIE_THEATER_COUNT_APM12","DAYS_BETWEEN_MOVIE_THEATER","DAYS_BETWEEN_MOVIE_THEATER_APM12","BAKERY_SPEND_SPEND_APM3","BAKERY_SPEND_SPEND_APM6","BAKERY_SPEND_SPEND_APM12","BAKERY_COUNT_APM3","BAKERY_COUNT_APM6","BAKERY_COUNT_APM12","DAYS_BETWEEN_BAKERY","DAYS_BETWEEN_BAKERY_APM12","GROCERIES_SPEND_APM3","GROCERIES_SPEND_APM6","GROCERIES_SPEND_APM12","GROCERIES_TRN_APM3","GROCERIES_TRN_APM6","GROCERIES_TRN_APM12","DAYS_BETWEEN_GROCERIES_APM12","TRAVEL_SPEND_APM12","TRAVEL_TRN_APM12","DAYS_BETWEEN_TRAVEL_APM12","MEDICAL_SPEND_APM3","MEDICAL_SPEND_APM6","MEDICAL_SPEND_APM12","MEDICAL_TRN_APM3","MEDICAL_TRN_APM6","MEDICAL_TRN_APM12","DAYS_BETWEEN_MEDICAL_APM12","BARS_AND_RESTAURANTS_SPEND_APM3","BARS_AND_RESTAURANTS_SPEND_APM6","BARS_AND_RESTAURANTS_SPEND_APM12","BARS_AND_RESTAURANTS_TRN_APM3","BARS_AND_RESTAURANTS_TRN_APM12","DAYS_BETWEEN_BARS_AND_RESTAURANTS_APM12","SPORTS_SPEND_APM3","SPORTS_SPEND_APM6","SPORTS_SPEND_APM12","SPORTS_TRN_APM3","SPORTS_TRN_APM6","SPORTS_TRN_APM12","DAYS_BETWEEN_SPORTS_APM12","FUEL_TRANSPORT_SPEND_APM3","FUEL_TRANSPORT_SPEND_APM6","FUEL_TRANSPORT_SPEND_APM12","FUEL_TRANSPORT_TRN_APM12","DAYS_BETWEEN_FUEL_APM12","HOME_IMPROVEMENT_SPEND_APM12","HOME_IMPROVEMENT_TRN_APM12","DAYS_BETWEEN_HOME_IMPROVEMENT_APM12","FASHION_SPEND_APM12","FASHION_TRN_APM12","DAYS_BETWEEN_CLOTHING_APM12","LIFESTYLE_SPENDER","ESAVVY_SPEND","ESAVVY_TRN_APM12","PHARMACY_SPEND_APM3","PHARMACY_SPEND_APM6","PHARMACY_SPEND_APM12","PHARMACY_COUNT_APM3","PHARMACY_COUNT_APM6","PHARMACY_COUNT_APM12","DAYS_BETWEEN_PHARMACY","DAYS_BETWEEN_PHARMACY_APM12"]
output_labels = ['Y_HYPERTENSION_DX_DATE_3YR','Y_DIABETES_DX_DATE_NEXT_3YR','Y_HYPERLIPIDEMIA_DX_DATE_3YR','Y_CAD_DX_DATE_3YR']
# Data
filepath = '/Users/thomas45/dev/data/predict/intfile0.csv'
print 'Reading from ' + filepath
data = pd.read_csv(filepath,low_memory=True)
# Extract inputs + labels
data = data[input_labels+output_labels]
# Extract DEG code
data['DEG'] = (data['DEG_CODE'].str.slice(0,3)).str.upper()
data.drop('DEG_CODE',axis=1,inplace=True)
data['PREV_DEG'] = (data['PREV_DEG_CODE_1'].str.slice(0,3)).str.upper()
data.drop('PREV_DEG_CODE_1',axis=1,inplace=True)
# set null to zero
data.fillna(0,inplace=True)
# Columns with NULL 
data.isnull().values.any()
# Encode 
data = one_hot_dataframe(data)
# double check size
print 'Number rows %d'%data.shape[0]
print 'Input data %d'%data.shape[1]
for col in data.columns:
	data[col] = pd.to_numeric(data[col],errors='coerce')
# Normalise
data.ix[:,1:len(data.columns)] = normalise(data.ix[:,1:len(data.columns)])
# Pickle pickle
#print 'Reading pickle'
#db = pd.read_pickle('predict.pkl')
# append to existing data frame
#db.append(data, ignore_index=True)
# Write pickle
data.to_pickle('predict.pkl')
